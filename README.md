# Kalmyk Image DH Analysis

Подробное руководство для начинающего пользователя. Ниже описаны шаги, которые нужно выполнить после открытия проекта в PyCharm на Windows, чтобы запустить полный анализ корпуса.

---

## 1. Что делает проект

Проект анализирует англоязычные травелоги о Сибири и Алтае (1864–1919) и исследует образы калмыков. Автоматически выполняются:

- поиск упоминаний этнонимов (Kalmyk, Kalmuk и варианты);
- извлечение контекстов (предложение ± три соседних);
- морфологический и семантический анализ (spaCy + DeepSeek);
- формирование таблицы PIRO (Place, Identity, Representation, Otherness);
- построение графиков и HTML-отчёта.

Все результаты сохраняются в папке `output/`, исходные тексты не изменяются.

---

## 2. Архитектура проекта и задачи модулей

### Основные сценарии
- `main.py` — главный конвейер. Загружает тексты, извлекает контексты этнонимов, запускает DeepSeek-аннотации, выполняет лингвистический анализ, строит визуализации, формирует PIRO-таблицу и HTML-отчёт. Во время выполнения выводит прогресс-бары для каждого этапа (классификация, тональность, резюме, переводы).
- `rerun_deepseek.py` — повторно запускает только DeepSeek-аннотации и переводы для сохранённых контекстов (`output/contexts_full.csv`). Используйте, если нужно обновить результаты без полного прогонки пайплайна (`python rerun_deepseek.py --force`).
- `scripts/generate_metadata_from_filenames.py` — автоматически формирует `data/metadata.csv` по именам файлов в `data/texts/`.

### Каталог `src/`
- `utils.py` — загрузка и очистка текстов, токенизация предложений, чтение этнонимов, метаданных, стоп-слов, хэширование текста.
- `extract_contexts.py` — поиск этнонимов во всех предложениях, формирование контекстов ±3 предложения, сохранение `output/contexts.csv`.
- `linguistic_analysis.py` — spaCy-анализ контекстов (POS, леммы, топонимы), экспорт `output/collocations.csv`.
- `deepseek_module.py` — универсальный клиент DeepSeek. Через `/v1/chat/completions` выполняет четыре задачи:
  - `classify_context` — семантические категории образа (ethnographic, functional, evaluative, religious, imperial);
  - `detect_sentiment` — тональность (positive, neutral, negative, ambivalent);
  - `summarize_context` — краткие английские резюме;
  - `translate_to_russian` — перевод итоговых меток и резюме на русский.

  Модуль:
  - делает до 3 повторов с задержкой;
  - кэширует ответы в `output/deepseek_responses.jsonl` (без повторных трат токенов);
  - использует ключ из `.env` или переменной окружения.

- `piro_table.py` — формирует PIRO-таблицу (англо- и русскоязычные столбцы Representation/Otherness/Summary), сохраняет `output/piro_table.xlsx`.
- `visualization.py` — строит графики: частота упоминаний по годам, wordcloud, сеть «автор–этноним–топоним», распределение категорий и стековую диаграмму тональностей по авторам.
- `report.py` — генерирует HTML-отчёт с таблицами, визуализациями и двуязычными аннотациями.

---

## 2. Структура папок (ориентир)

```
Kalmyk Image DH Analysis/
├── data/
│   ├── texts/               # сюда кладём .txt с травелогами
│   ├── metadata.csv         # таблица с автором, годом, названием, источником
│   ├── ethnonyms.txt        # список этнонимов (уже заполнен)
│   └── stopwords_en.txt     # список стоп-слов (можно расширять)
├── src/                     # исходный код проекта
│   ├── utils.py
│   ├── extract_contexts.py
│   ├── linguistic_analysis.py
│   ├── piro_table.py
│   ├── deepseek_module.py
│   ├── visualization.py
│   └── report.py
├── output/                  # сюда будут сохранены результаты
│   └── figures/             # графики и wordcloud
├── main.py                  # главный сценарий запуска
├── requirements.txt         # список зависимостей Python
├── .env                     # здесь будет ключ DeepSeek
└── README.md                # текущее руководство
```

---

## 3. Подготовка данных

1. **Тексты**: поместите все файлы травелогов в `data/texts/`. Формат имени: `Автор_Год_Название.txt` (пример: `Michie_1864_SiberianOverlandRoute.txt`).
2. **Метаданные**: откройте `data/metadata.csv` в Excel или LibreOffice Calc и заполните столбцы:
   - `author` — автор текста;
   - `year` — год публикации (число);
   - `title` — заголовок;
   - `source` — откуда получен текст (например, архив, ссылка).
   Каждая строка должна соответствовать файлу из `data/texts/`.
3. **Этнонимы и стоп-слова** уже заготовлены, при необходимости добавьте свои варианты.

---

## 4. Первичный запуск PyCharm

1. Запустите PyCharm.
2. В меню выберите **`File → Open...`**, укажите папку `Kalmyk Image DH Analysis` и нажмите **OK**.
3. PyCharm предложит доверять проекту — нажмите **Trust Project**.
4. Дождитесь индексации (может занять пару минут).

---

## 5. Создание виртуальной среды (рекомендуется)

1. В PyCharm откройте меню **`File → Settings...`** (или `Ctrl+Alt+S`).
2. Перейдите в раздел **`Project: Kalmyk Image DH Analysis → Python Interpreter`**.
3. Нажмите на значок шестерёнки справа и выберите **`Add...`**.
4. В разделе **`Virtualenv Environment`** проверьте, что выбран базовый интерпретатор (обычно `Python 3.x`), и что путь создания по умолчанию (`.../Kalmyk Image DH Analysis/.venv`). Нажмите **OK**.
5. После создания окружения PyCharm переключится на него автоматически.

---

## 6. Установка зависимостей через PyCharm

1. В нижней панели PyCharm откройте вкладку **Terminal** (или нажмите `Alt+F12`).
2. Убедитесь, что виртуальная среда активирована (в приглашении терминала должно быть `(venv)` или `.venv`). Если нет — выполните:
   ```powershell
   .venv\Scripts\activate
   ```
3. Установите зависимости:
   ```powershell
   pip install -r requirements.txt
   ```
4. Установите язык для spaCy (нужно один раз):
   ```powershell
   python -m spacy download en_core_web_sm
   ```

Если появления ошибок нет — зависимости установлены успешно.

---

## 7. Настройка ключа DeepSeek

1. Получите API-ключ DeepSeek (если ещё нет) и скопируйте его.
2. В PyCharm найдите файл `.env` (если не видите, включите отображение скрытых файлов: `View → Appearance → Nice tree view` отключить, затем `View → Appearance → Details in Tree Views` — главное, чтобы `.env` был виден).
3. Откройте `.env` и впишите свой ключ вместо заглушки:
   ```
   DEEPSEEK_API_KEY=ваш_ключ
   ```
4. Сохраните файл (`Ctrl+S`). Ключ больше нигде указывать не нужно — скрипт прочитает его автоматически.

> **Важно:** без ключа DeepSeek запросы к API будут пропускаться, и в отчёте появятся пометки «unavailable». Для полноценных результатов ключ обязателен.

---

## 8. Запуск анализа из PyCharm

1. Убедитесь, что терминал открыт и виртуальная среда активна.
2. Выполните команду:
   ```powershell
   python main.py
   ```
3. Во время работы скрипт:
   - считает все тексты из `data/texts/`;
   - сформирует `output/contexts.csv` (базовый набор) и затем `output/contexts_full.csv` (билингвальный корпус) с найденными контекстами;
   - отправит контексты в DeepSeek (с учётом кэширования);
   - выполнит морфологический анализ и извлечёт топонимы;
   - построит графики в `output/figures/`;
   - соберёт `output/piro_table.xlsx`;
   - сгенерирует HTML-отчёт `output/report.html`.
4. По завершении в терминале появится сообщение:
   ```
   ✅ Analysis complete. Results saved in /output/
   ```

Если видите предупреждения (Warning) о пропущенных данных — проверьте заполненность `metadata.csv` и наличие текста в `data/texts/`.

---

## 9. Что смотреть после запуска

- `output/contexts.csv` — исходные контексты с метаданными (без аннотаций).
- `output/contexts_full.csv` — полный билингвальный корпус с колонками:
  - `semantic_label`, `attitude`, `summary_en`;
  - `semantic_label_ru`, `attitude_ru`, `summary_ru`.
- `output/collocations.csv` — частотные сочетания прилагательных и глаголов вокруг этнонимов.
- `output/piro_table.xlsx` — PIRO-таблица (Place, Identity, Representation, Otherness + русскоязычные поля).
- `output/deepseek_responses.jsonl` — кэш ответов DeepSeek (ключ задачи + текстовый ответ).
- `output/figures/` — пять визуализаций: частота по годам, wordcloud, сеть, распределение категорий, тональность по авторам.
- `output/report.html` — готовый отчёт. Откройте двойным щелчком прямо в PyCharm или через браузер (правый клик → Open in Browser).

---

## 10. Повторный запуск и обновление данных

1. Добавьте новые файлы в `data/texts/` и обновите `metadata.csv` (можно просто дописать строку для нового текста).
2. При необходимости расширьте списки `ethnonyms.txt` и `stopwords_en.txt` (каждый пункт с новой строки).
3. Снова запустите `python main.py`. Старые результаты будут перезаписаны новыми, кэш DeepSeek пополнится, но повторных запросов для уже обработанных контекстов не потребуется.

---

## 11. Полезные советы

- Если появляется ошибка `ModuleNotFoundError`, убедитесь, что активирована виртуальная среда и зависимости установлены.
- Если `python -m spacy download en_core_web_sm` не запускается, проверьте подключение к интернету или попробуйте команду повторить.
- Для анализа можно использовать только часть текстов (например, поместить 2–3 файла) — скрипт работает с любым количеством.
- Кэш DeepSeek (`output/deepseek_responses.jsonl`) можно сохранить отдельно, чтобы не запрашивать повторно при переустановке проекта.

---

## 12. Мини-шпаргалка по командам (Windows PowerShell)

```powershell
# активация виртуальной среды
.venv\Scripts\activate

# установка зависимостей
pip install -r requirements.txt

# загрузка модели spaCy (один раз)
python -m spacy download en_core_web_sm

# запуск анализа
python main.py
```

---

Проект полностью автономный, ничего не скачивает без вашего ведома (кроме модели spaCy и обращений к DeepSeek при наличии ключа). Все шаги легко повторить: достаточно сохранить структуру папок, `.env` с ключом и `output/` с кэшем.

Для быстрой переаннотации используйте:
```powershell
python rerun_deepseek.py --force
```
Скрипт обновит DeepSeek-колонки (EN/RU) в `output/contexts_full.csv`, не затрагивая остальные этапы пайплайна.

